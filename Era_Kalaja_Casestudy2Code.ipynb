{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa90d0f1",
   "metadata": {},
   "source": [
    "For this case study, you will perform a classification task on a WiFi dataset. You will use WLAN fingerprints to identify the location of a user. You will identify locations using the building numbers and floor numbers only. \n",
    "\n",
    "You will also explore the question, \"is more data useful for a classification task?\"\n",
    "\n",
    "The dataset you will use can be found on: https://archive.ics.uci.edu/ml/datasets/ujiindoorloc .\n",
    "\n",
    "**\\[Step 1\\]** Once you examine the data sets, you will find that there is a training set and a validation set. However, you must also create a test set that has the same number of samples as the validation set. You can select and remove random samples from the training set and use them to create a test set. The test set should not be used in the training process or to optimize the parameters of any algorithm you use. The test set should only be used to report the final performance of a model whenever necessary.\n",
    "\n",
    "You may need to determine the features and labels of your model. You can also do some engineering on features and labels if necessary.\n",
    "\n",
    "**\\[Step 2\\]** But, which algorithm should you use with your model? You can refer to the scikit-learn cheat sheet: https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html, and try three algorithms. Some suggestions are: LinearSVC, Logistic Regression, KNN classifier, SVC, Random Forest (as an example of Ensemble Learning) etc. Perform one experiment using each and observe the performance of each model. Note which is the best performing model.\n",
    "\n",
    "**\\[Step 3\\]** Once the previous step is done, observe if more data is useful for a classification task. For this, randomly select 20% of the training samples, but keep the size of the test set the same. You wil not use the validation set in this step as you will not optimize the model in any way. Note the performance. Then also try with 40%, 60%, 80% and 100% of the training samples. Perform three experiments for each selection. This means, for 20% you will do three experiments, 40% three experiments etc. Find the average of three experiments for each selection and plot them using a method of your choice.\n",
    "\n",
    "**\\[Step 4\\]** Publish your finding in presentation slides. Like case study 1, three of you will be randomly chosen to present your work in front of the class. The slides should inform the audience about:\n",
    "\n",
    "* the objective of the case study\n",
    "* the data (features and labels)\n",
    "* things you have done (e.g. why you selected a specific classification model)\n",
    "* challenges you have faced that might be interesting to your classmates\n",
    "* your findings\n",
    "\n",
    "\n",
    "**Things to note**:\n",
    "\n",
    "* **Type of task**: classification\n",
    "* **Features**: you choose\n",
    "* **Feature engineering**: You are welcome to do so.\n",
    "* **Labels**: User locations. Use building and floor IDs, but ignore the SPACEID column.\n",
    "\n",
    "* In some cases, normalization may result in reduced accuracy.\n",
    "* You must write enough comments so that anybody with some programming knowledge can understand your code.\n",
    "\n",
    "Also,\n",
    "* This is not a group project. But if you think you will benefit from working with a partner, you are welcome to find a partner. No points will be deducted if you choose to do so. However, you must inform Himan (the TA) and me (Prof. Ghoshal) by **September 25, 2023** in that case.\n",
    "\n",
    "\n",
    "**Grading Criteria**:\n",
    "\n",
    "* [15 + 15] Data set preparation: Choosing your $X$ (features) and $y$ (label). Feature Engineering.\n",
    "* [15 + 15 + 15] Three experiments using three algorithms.  \n",
    "* [15] Observing the effects of more data using five sets of random samples of different sizes from the training set. \n",
    "* [10] Presentation slides and presentation.\n",
    "\n",
    "**What to submit**:\n",
    "\n",
    "Put the Jupyter Notebook file and the .csv file in a folder. Then convert your presentation slides to a PDF file and put it in the same folder. Zip the folder. After zipping, it should have the extension .zip. The name of the .zip file should be firstname_lastname_casestudy_2.zip . Upload the .zip file on Canvas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2b9b93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries \n",
    "import numpy as np  #used for plotting \n",
    "import pandas as pd #used for dataset manipulation\n",
    "from sklearn.preprocessing import StandardScaler #used for standardization in kth nearest neighbors model\n",
    "from sklearn import model_selection #used for cross validation steps\n",
    "from sklearn.linear_model import LinearRegression  \n",
    "from sklearn.model_selection import train_test_split # used for splitting the training data and testing data\n",
    "#import seaborn as sns \n",
    "import matplotlib.pyplot as plt #used for scatter plot average of training sets\n",
    "from sklearn.metrics import accuracy_score #used to print accuracy of models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2b581f",
   "metadata": {},
   "source": [
    "# Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42b2b753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load entire dataset \n",
    "whole_data = pd.read_csv('trainingData.csv') #contains the entire training data set unfiltered and before the split\n",
    "data_validate = pd.read_csv('validationData.csv') # contains the entire validation data set unfiltered \n",
    "whole_data_backup = whole_data.copy()  #after loading all the data saving a backup variable to store it whole \n",
    "#whole_data # <- printing to ensure that data was brought in properly, now lets start thinking about features vs target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79fa9b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WAP001</th>\n",
       "      <th>WAP002</th>\n",
       "      <th>WAP003</th>\n",
       "      <th>WAP004</th>\n",
       "      <th>WAP005</th>\n",
       "      <th>WAP006</th>\n",
       "      <th>WAP007</th>\n",
       "      <th>WAP008</th>\n",
       "      <th>WAP009</th>\n",
       "      <th>WAP010</th>\n",
       "      <th>...</th>\n",
       "      <th>WAP520</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>FLOOR</th>\n",
       "      <th>BUILDINGID</th>\n",
       "      <th>SPACEID</th>\n",
       "      <th>RELATIVEPOSITION</th>\n",
       "      <th>USERID</th>\n",
       "      <th>PHONEID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19937.000000</td>\n",
       "      <td>19937.000000</td>\n",
       "      <td>19937.0</td>\n",
       "      <td>19937.0</td>\n",
       "      <td>19937.000000</td>\n",
       "      <td>19937.000000</td>\n",
       "      <td>19937.000000</td>\n",
       "      <td>19937.000000</td>\n",
       "      <td>19937.000000</td>\n",
       "      <td>19937.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>19937.0</td>\n",
       "      <td>19937.000000</td>\n",
       "      <td>1.993700e+04</td>\n",
       "      <td>19937.000000</td>\n",
       "      <td>19937.000000</td>\n",
       "      <td>19937.000000</td>\n",
       "      <td>19937.000000</td>\n",
       "      <td>19937.000000</td>\n",
       "      <td>19937.000000</td>\n",
       "      <td>1.993700e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>99.823644</td>\n",
       "      <td>99.820936</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.613733</td>\n",
       "      <td>97.130461</td>\n",
       "      <td>94.733661</td>\n",
       "      <td>93.820234</td>\n",
       "      <td>94.693936</td>\n",
       "      <td>99.163766</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-7464.275947</td>\n",
       "      <td>4.864871e+06</td>\n",
       "      <td>1.674575</td>\n",
       "      <td>1.212820</td>\n",
       "      <td>148.429954</td>\n",
       "      <td>1.833024</td>\n",
       "      <td>9.068014</td>\n",
       "      <td>13.021869</td>\n",
       "      <td>1.371421e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.866842</td>\n",
       "      <td>5.798156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.615657</td>\n",
       "      <td>22.931890</td>\n",
       "      <td>30.541335</td>\n",
       "      <td>33.010404</td>\n",
       "      <td>30.305084</td>\n",
       "      <td>12.634045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123.402010</td>\n",
       "      <td>6.693318e+01</td>\n",
       "      <td>1.223078</td>\n",
       "      <td>0.833139</td>\n",
       "      <td>58.342106</td>\n",
       "      <td>0.372964</td>\n",
       "      <td>4.988720</td>\n",
       "      <td>5.362410</td>\n",
       "      <td>5.572054e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-97.000000</td>\n",
       "      <td>-90.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-97.000000</td>\n",
       "      <td>-98.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-98.000000</td>\n",
       "      <td>-98.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-7691.338400</td>\n",
       "      <td>4.864746e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.369909e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-7594.737000</td>\n",
       "      <td>4.864821e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.371056e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-7423.060900</td>\n",
       "      <td>4.864852e+06</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.371716e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-7359.193000</td>\n",
       "      <td>4.864930e+06</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.371721e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-7300.818990</td>\n",
       "      <td>4.865017e+06</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.371738e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 529 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             WAP001        WAP002   WAP003   WAP004        WAP005  \\\n",
       "count  19937.000000  19937.000000  19937.0  19937.0  19937.000000   \n",
       "mean      99.823644     99.820936    100.0    100.0     99.613733   \n",
       "std        5.866842      5.798156      0.0      0.0      8.615657   \n",
       "min      -97.000000    -90.000000    100.0    100.0    -97.000000   \n",
       "25%      100.000000    100.000000    100.0    100.0    100.000000   \n",
       "50%      100.000000    100.000000    100.0    100.0    100.000000   \n",
       "75%      100.000000    100.000000    100.0    100.0    100.000000   \n",
       "max      100.000000    100.000000    100.0    100.0    100.000000   \n",
       "\n",
       "             WAP006        WAP007        WAP008        WAP009        WAP010  \\\n",
       "count  19937.000000  19937.000000  19937.000000  19937.000000  19937.000000   \n",
       "mean      97.130461     94.733661     93.820234     94.693936     99.163766   \n",
       "std       22.931890     30.541335     33.010404     30.305084     12.634045   \n",
       "min      -98.000000    -99.000000    -98.000000    -98.000000    -99.000000   \n",
       "25%      100.000000    100.000000    100.000000    100.000000    100.000000   \n",
       "50%      100.000000    100.000000    100.000000    100.000000    100.000000   \n",
       "75%      100.000000    100.000000    100.000000    100.000000    100.000000   \n",
       "max      100.000000    100.000000    100.000000    100.000000    100.000000   \n",
       "\n",
       "       ...   WAP520     LONGITUDE      LATITUDE         FLOOR    BUILDINGID  \\\n",
       "count  ...  19937.0  19937.000000  1.993700e+04  19937.000000  19937.000000   \n",
       "mean   ...    100.0  -7464.275947  4.864871e+06      1.674575      1.212820   \n",
       "std    ...      0.0    123.402010  6.693318e+01      1.223078      0.833139   \n",
       "min    ...    100.0  -7691.338400  4.864746e+06      0.000000      0.000000   \n",
       "25%    ...    100.0  -7594.737000  4.864821e+06      1.000000      0.000000   \n",
       "50%    ...    100.0  -7423.060900  4.864852e+06      2.000000      1.000000   \n",
       "75%    ...    100.0  -7359.193000  4.864930e+06      3.000000      2.000000   \n",
       "max    ...    100.0  -7300.818990  4.865017e+06      4.000000      2.000000   \n",
       "\n",
       "            SPACEID  RELATIVEPOSITION        USERID       PHONEID  \\\n",
       "count  19937.000000      19937.000000  19937.000000  19937.000000   \n",
       "mean     148.429954          1.833024      9.068014     13.021869   \n",
       "std       58.342106          0.372964      4.988720      5.362410   \n",
       "min        1.000000          1.000000      1.000000      1.000000   \n",
       "25%      110.000000          2.000000      5.000000      8.000000   \n",
       "50%      129.000000          2.000000     11.000000     13.000000   \n",
       "75%      207.000000          2.000000     13.000000     14.000000   \n",
       "max      254.000000          2.000000     18.000000     24.000000   \n",
       "\n",
       "          TIMESTAMP  \n",
       "count  1.993700e+04  \n",
       "mean   1.371421e+09  \n",
       "std    5.572054e+05  \n",
       "min    1.369909e+09  \n",
       "25%    1.371056e+09  \n",
       "50%    1.371716e+09  \n",
       "75%    1.371721e+09  \n",
       "max    1.371738e+09  \n",
       "\n",
       "[8 rows x 529 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#steps to understand the data better before feature engineering\n",
    "whole_data.describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beda4589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19937 entries, 0 to 19936\n",
      "Columns: 529 entries, WAP001 to TIMESTAMP\n",
      "dtypes: float64(2), int64(527)\n",
      "memory usage: 80.5 MB\n"
     ]
    }
   ],
   "source": [
    "#steps to understand the data better before feature engineering\n",
    "whole_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "512f3fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1_2', '0_0', '2_3', '2_2', '2_4', '1_0', '1_1', '2_1', '1_3',\n",
       "       '2_0', '0_2', '0_1', '0_3'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#After further analysis: 100 means nothing detected, -104 means poorest signal, 0 means strongest signal\n",
    "\n",
    "#only want to use WAPs as my features since these indicate range\n",
    "WAP_columns = whole_data.columns[:520]  #storing the first 520 columns from the training set since these contain the 520 WAPs\n",
    "\n",
    "#since -104 is poorest signal, replace 100 values with -105 to show no signal\n",
    "whole_data[WAP_columns] = whole_data[WAP_columns].replace(100, -105)\n",
    "\n",
    "#to narrow down to one target instead of 2, combine the two attributes into a string: BUILDINGID_FLOOR\n",
    "#defining this as the target (Y)\n",
    "target = whole_data['BUILDINGID'].astype(str) + '_' + whole_data['FLOOR'].astype(str)\n",
    "\n",
    "#defining feature (x)\n",
    "features = whole_data[WAP_columns]\n",
    "\n",
    "target.unique() #checking what unique values we have in our target (i.e the combination of building id vs floors- there are 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28cf72af",
   "metadata": {},
   "outputs": [],
   "source": [
    "WAP_col = data_validate.columns[:520] \n",
    "#since -104 is lowest, replace 100 values with -105 to show no signal\n",
    "data_validate[WAP_col] = data_validate[WAP_col].replace(100, -105)\n",
    "\n",
    "#to narrow down to one target instead of 2, combine the two attributes into a string: BUILDINGID_FLOOR\n",
    "#defining this as the target (y)\n",
    "val_target = data_validate['BUILDINGID'].astype(str) + '_' + data_validate['FLOOR'].astype(str)\n",
    "\n",
    "#defining feature (x)\n",
    "val_feature = data_validate[WAP_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bd912c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset features and target into a test set and training set, using 0.0557 as test size so there will be 1111 = validation size\n",
    "SEED = 0   #use this value to reproduce the same random selection \n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.0557, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f68a7bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape (1111, 520)\n",
      "train shape (18826, 520)\n"
     ]
    }
   ],
   "source": [
    "#understanding shape of input data to prep for classification model \n",
    "print(\"test shape\", features_test.shape)\n",
    "print(\"train shape\", features_train.shape)\n",
    "#step 1 complete "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f25eb9",
   "metadata": {},
   "source": [
    "# Step 2: picking 3 machine learning models: SVC, KNN, Random Forest "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f2fff5",
   "metadata": {},
   "source": [
    "Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50c62d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#start with random forest classifier: \n",
    "from sklearn.ensemble import RandomForestClassifier #gives access to library with needed algorithms/functions\n",
    "\n",
    "#rfc will be the random forest classifier \n",
    "#since random forest uses random subset, set the random state to a specific value to make results reproducable \n",
    "rfc = RandomForestClassifier(n_estimators=13, random_state=SEED) #used 13 as n_estimators since we have 13 unique target values, tested different options and this had highest accuracy\n",
    "rfc.fit(features_train, target_train) #training model on training dataset\n",
    "\n",
    "rfc_predict_target = rfc.predict(features_test) #testing model on test set, tries to predict targets for given features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10afad7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0_0       1.00      0.97      0.98        66\n",
      "         0_1       0.96      1.00      0.98        71\n",
      "         0_2       1.00      0.99      0.99        74\n",
      "         0_3       1.00      0.99      0.99        82\n",
      "         1_0       1.00      1.00      1.00        80\n",
      "         1_1       1.00      1.00      1.00        96\n",
      "         1_2       1.00      1.00      1.00        86\n",
      "         1_3       0.90      1.00      0.95        52\n",
      "         2_0       1.00      0.96      0.98       112\n",
      "         2_1       0.99      1.00      1.00       109\n",
      "         2_2       1.00      0.99      0.99        94\n",
      "         2_3       1.00      1.00      1.00       139\n",
      "         2_4       1.00      1.00      1.00        50\n",
      "\n",
      "    accuracy                           0.99      1111\n",
      "   macro avg       0.99      0.99      0.99      1111\n",
      "weighted avg       0.99      0.99      0.99      1111\n",
      "\n",
      "0.990999099909991\n"
     ]
    }
   ],
   "source": [
    "#testing accuracy of rfc:\n",
    "from sklearn.metrics import classification_report #import class for a full report of model's performance\n",
    "\n",
    "print(classification_report(target_test,rfc_predict_target)) #print full report of model's performance and analyze results \n",
    "\n",
    "accuracy = accuracy_score(target_test, rfc_predict_target) #calculate exact accuracy of model (this value won't be rounded to 2 decimal places)\n",
    "print(accuracy) \n",
    "#accuracy looks high across all, no need to further tune "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "002b320a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score: 0.8433967599886882\n"
     ]
    }
   ],
   "source": [
    "#cross validation for rfc\n",
    "from sklearn.model_selection import cross_val_score \n",
    "\n",
    "scores = cross_val_score(rfc, val_feature, val_target, cv=5) #5 fold cross validation used to tune the model \n",
    "print(\"Cross Validation Score:\", scores.mean())\n",
    "#pretty good cross validation score, no need to further tune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e952b9c3",
   "metadata": {},
   "source": [
    "Kth Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e41023b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd model: kth nearest neighbors (KNN)\n",
    "from sklearn.neighbors import KNeighborsClassifier #gives access to library with needed algorithms/functions\n",
    "\n",
    "stdscale = StandardScaler() #instance of standardScaler class to standardize features \n",
    "stdscale.fit(features_train) #fit using standard deviation and mean of features  \n",
    "\n",
    "#standardize features and target values as defined by the standardScaler class:\n",
    "features_train = stdscale.transform(features_train) \n",
    "features_test = stdscale.transform(features_test)\n",
    "\n",
    "knc = KNeighborsClassifier()\n",
    "knc.fit(features_train, target_train) #training model on training set \n",
    "\n",
    "knc_predict_target = knc.predict(features_test) #testing model by predicting target values of test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a233246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0_0       0.98      0.98      0.98        66\n",
      "         0_1       0.97      0.97      0.97        71\n",
      "         0_2       0.96      0.96      0.96        74\n",
      "         0_3       0.98      0.98      0.98        82\n",
      "         1_0       1.00      1.00      1.00        80\n",
      "         1_1       1.00      1.00      1.00        96\n",
      "         1_2       0.99      1.00      0.99        86\n",
      "         1_3       1.00      0.96      0.98        52\n",
      "         2_0       0.98      1.00      0.99       112\n",
      "         2_1       0.97      0.95      0.96       109\n",
      "         2_2       0.98      0.97      0.97        94\n",
      "         2_3       0.98      0.99      0.99       139\n",
      "         2_4       1.00      1.00      1.00        50\n",
      "\n",
      "    accuracy                           0.98      1111\n",
      "   macro avg       0.98      0.98      0.98      1111\n",
      "weighted avg       0.98      0.98      0.98      1111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(target_test, knc_predict_target))\n",
    "#accuracy looks good no need to further tune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f5154df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross validation for knn tuning\n",
    "#defining target (y)\n",
    "#knc_scores = cross_val_score(knc, val_feature, val_feature, cv=5)\n",
    "# Print the cross-validation scores\n",
    "#print(\"Cross-validation scores:\", knc_scores)\n",
    "#print(\"Mean cross-validation score:\", knc_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c01c2af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing whether this would increase accuracy \n",
    "#knc1 = KNeighborsClassifier(n_neighbors=8)\n",
    "#knc1.fit(features_train, target_train)\n",
    "\n",
    "#knc_predict_target1 = knc1.predict(features_test)\n",
    "#print(classification_report(target_test, knc_predict_target1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc15724",
   "metadata": {},
   "source": [
    "SVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da37fe6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd model: SVC\n",
    "from sklearn.svm import SVC #gives access to library with needed algorithms/functions\n",
    "\n",
    "svc = SVC(kernel='linear') #set to linear since there should be straight line boundaries between classification types(target values)\n",
    "svc.fit(features_train, target_train) #train model on training set \n",
    "\n",
    "svc_predict_target = svc.predict(features_test) #test model by predicting associated test target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "225131e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0_0       0.98      0.98      0.98        66\n",
      "         0_1       0.99      0.99      0.99        71\n",
      "         0_2       0.99      1.00      0.99        74\n",
      "         0_3       1.00      0.99      0.99        82\n",
      "         1_0       1.00      0.99      0.99        80\n",
      "         1_1       0.99      1.00      0.99        96\n",
      "         1_2       0.99      1.00      0.99        86\n",
      "         1_3       0.91      0.98      0.94        52\n",
      "         2_0       1.00      0.96      0.98       112\n",
      "         2_1       1.00      1.00      1.00       109\n",
      "         2_2       1.00      1.00      1.00        94\n",
      "         2_3       1.00      1.00      1.00       139\n",
      "         2_4       1.00      1.00      1.00        50\n",
      "\n",
      "    accuracy                           0.99      1111\n",
      "   macro avg       0.99      0.99      0.99      1111\n",
      "weighted avg       0.99      0.99      0.99      1111\n",
      "\n",
      "0.990999099909991\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(target_test,svc_predict_target))\n",
    "accuracy = accuracy_score(target_test, svc_predict_target)\n",
    "print(accuracy)\n",
    "#accuracy looks great no need to further tune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "477e29de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score: 0.8955803336969256\n"
     ]
    }
   ],
   "source": [
    "#cross validation \n",
    "svcscores = cross_val_score(svc, val_feature, val_target, cv=5)\n",
    "print(\"Cross Validation Score:\", svcscores.mean())\n",
    "#cross validation score looks good no need to further tune "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5087c7d",
   "metadata": {},
   "source": [
    "# Result from step 2: the best algorithm for this data set is SVC due to it's high accuracy on test data and high cross validation mean score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1784b650",
   "metadata": {},
   "source": [
    "# Step 3: 20%, 40%, 60%, 80%, 100% of Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6129c6e",
   "metadata": {},
   "source": [
    "Using only 20% of data for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5737bb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape (1111, 520)\n",
      "train shape (3987, 520)\n"
     ]
    }
   ],
   "source": [
    "# using 20% of the dataset: \n",
    "#randomly select 20% of training data to be included \n",
    "feature_train20, feature_test20, target_train20, target_test20 = train_test_split(features, target, test_size=0.0557, train_size=0.2, random_state=SEED)\n",
    "print(\"test shape\", feature_test20.shape)\n",
    "print(\"train shape\", feature_train20.shape)\n",
    "#ensuring correct number of values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a15e7d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0_0       0.98      0.97      0.98        66\n",
      "         0_1       0.95      0.97      0.96        71\n",
      "         0_2       0.97      0.97      0.97        74\n",
      "         0_3       1.00      0.98      0.99        82\n",
      "         1_0       0.99      0.97      0.98        80\n",
      "         1_1       0.98      0.99      0.98        96\n",
      "         1_2       0.99      1.00      0.99        86\n",
      "         1_3       0.98      0.96      0.97        52\n",
      "         2_0       0.99      0.99      0.99       112\n",
      "         2_1       0.97      1.00      0.99       109\n",
      "         2_2       1.00      0.93      0.96        94\n",
      "         2_3       0.95      1.00      0.98       139\n",
      "         2_4       1.00      0.96      0.98        50\n",
      "\n",
      "    accuracy                           0.98      1111\n",
      "   macro avg       0.98      0.98      0.98      1111\n",
      "weighted avg       0.98      0.98      0.98      1111\n",
      "\n",
      "0.9792979297929792\n"
     ]
    }
   ],
   "source": [
    "#random forest model on 20% of the data:\n",
    "#repeat steps from earlier excluding cross validation on smaller training set \n",
    "rfc20 = RandomForestClassifier(n_estimators=13, \n",
    "                             random_state=SEED)\n",
    "rfc20.fit(feature_train20, target_train20)\n",
    "\n",
    "rfc20_predict_target = rfc20.predict(feature_test20)\n",
    "\n",
    "print(classification_report(target_test20,rfc20_predict_target))\n",
    "accuracyrfc20 = accuracy_score(target_test20, rfc20_predict_target)\n",
    "print(accuracyrfc20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "804ec8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0_0       0.97      0.95      0.96        66\n",
      "         0_1       0.93      0.94      0.94        71\n",
      "         0_2       0.90      0.95      0.92        74\n",
      "         0_3       0.97      0.93      0.95        82\n",
      "         1_0       0.92      0.99      0.95        80\n",
      "         1_1       0.99      0.94      0.96        96\n",
      "         1_2       0.99      0.98      0.98        86\n",
      "         1_3       0.98      0.96      0.97        52\n",
      "         2_0       0.97      1.00      0.99       112\n",
      "         2_1       0.98      0.94      0.96       109\n",
      "         2_2       0.95      0.98      0.96        94\n",
      "         2_3       0.96      0.98      0.97       139\n",
      "         2_4       1.00      0.96      0.98        50\n",
      "\n",
      "    accuracy                           0.96      1111\n",
      "   macro avg       0.96      0.96      0.96      1111\n",
      "weighted avg       0.96      0.96      0.96      1111\n",
      "\n",
      "0.9621962196219622\n"
     ]
    }
   ],
   "source": [
    "# kth nearest neighbors (KNN) on 20% of data:\n",
    "#repeat steps from earlier excluding cross validation on smaller training set \n",
    "stdscale.fit(feature_train20)\n",
    "feature_train20 = stdscale.transform(feature_train20)\n",
    "feature_test20 = stdscale.transform(feature_test20)\n",
    "\n",
    "knc20 = KNeighborsClassifier()\n",
    "knc20.fit(feature_train20, target_train20)\n",
    "\n",
    "knc20_predict_target = knc20.predict(feature_test20)\n",
    "\n",
    "print(classification_report(target_test20, knc20_predict_target))\n",
    "accuracy20knn = accuracy_score(target_test20, knc20_predict_target)\n",
    "print(accuracy20knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e843299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0_0       0.96      0.97      0.96        66\n",
      "         0_1       0.96      0.96      0.96        71\n",
      "         0_2       0.99      0.99      0.99        74\n",
      "         0_3       1.00      0.99      0.99        82\n",
      "         1_0       1.00      0.99      0.99        80\n",
      "         1_1       0.99      1.00      0.99        96\n",
      "         1_2       0.99      0.99      0.99        86\n",
      "         1_3       0.98      0.96      0.97        52\n",
      "         2_0       0.99      0.99      0.99       112\n",
      "         2_1       0.99      1.00      1.00       109\n",
      "         2_2       1.00      1.00      1.00        94\n",
      "         2_3       1.00      1.00      1.00       139\n",
      "         2_4       1.00      1.00      1.00        50\n",
      "\n",
      "    accuracy                           0.99      1111\n",
      "   macro avg       0.99      0.99      0.99      1111\n",
      "weighted avg       0.99      0.99      0.99      1111\n",
      "\n",
      "0.9891989198919892\n"
     ]
    }
   ],
   "source": [
    "# svc on 20% of data:\n",
    "#repeat steps from earlier excluding cross validation on smaller training set \n",
    "svc20 = SVC(kernel='linear')\n",
    "svc20.fit(feature_train20, target_train20)\n",
    "\n",
    "svc20_predict_target = svc20.predict(feature_test20)\n",
    "\n",
    "print(classification_report(target_test20,svc20_predict_target))\n",
    "accuracysvc20 = accuracy_score(target_test20, svc20_predict_target)\n",
    "print(accuracysvc20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd911d53",
   "metadata": {},
   "source": [
    "Mean accuracy for all three experiments using 20% of data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a95ba0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9768976897689768\n"
     ]
    }
   ],
   "source": [
    "# computing mean accuracy score for using 20% of data to train\n",
    "average20 = (accuracyrfc20 + accuracy20knn + accuracysvc20) / 3\n",
    "print(average20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd105c6b",
   "metadata": {},
   "source": [
    "Using only 40% of data for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5dbda689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape (1111, 520)\n",
      "train shape (7974, 520)\n"
     ]
    }
   ],
   "source": [
    "# using 40% of the dataset:\n",
    "#randomly select 40% of training data to be included \n",
    "feature_train40, feature_test40, target_train40, target_test40 = train_test_split(features, target, test_size=0.0557, train_size=0.4, random_state=SEED)\n",
    "\n",
    "print(\"test shape\", feature_test40.shape)\n",
    "print(\"train shape\", feature_train40.shape)\n",
    "#ensuring correct number of values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7975cb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0_0       0.98      0.97      0.98        66\n",
      "         0_1       0.97      1.00      0.99        71\n",
      "         0_2       0.99      0.99      0.99        74\n",
      "         0_3       1.00      0.99      0.99        82\n",
      "         1_0       0.99      1.00      0.99        80\n",
      "         1_1       1.00      0.99      0.99        96\n",
      "         1_2       0.99      1.00      0.99        86\n",
      "         1_3       0.91      0.98      0.94        52\n",
      "         2_0       1.00      0.96      0.98       112\n",
      "         2_1       0.98      1.00      0.99       109\n",
      "         2_2       1.00      0.98      0.99        94\n",
      "         2_3       0.99      1.00      1.00       139\n",
      "         2_4       1.00      0.98      0.99        50\n",
      "\n",
      "    accuracy                           0.99      1111\n",
      "   macro avg       0.99      0.99      0.99      1111\n",
      "weighted avg       0.99      0.99      0.99      1111\n",
      "\n",
      "0.9873987398739874\n"
     ]
    }
   ],
   "source": [
    "#random forest model on 40% of the data\n",
    "rfc40 = RandomForestClassifier(n_estimators=13, \n",
    "                             random_state=SEED)\n",
    "rfc40.fit(feature_train40, target_train40)\n",
    "\n",
    "rfc40_predict_target = rfc40.predict(feature_test40)\n",
    "\n",
    "print(classification_report(target_test40,rfc40_predict_target))\n",
    "accuracyrfc40 = accuracy_score(target_test40, rfc40_predict_target)\n",
    "print(accuracyrfc40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "902a083c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0_0       0.98      0.97      0.98        66\n",
      "         0_1       0.95      0.99      0.97        71\n",
      "         0_2       0.93      0.95      0.94        74\n",
      "         0_3       0.96      0.93      0.94        82\n",
      "         1_0       1.00      1.00      1.00        80\n",
      "         1_1       1.00      1.00      1.00        96\n",
      "         1_2       0.97      1.00      0.98        86\n",
      "         1_3       1.00      0.94      0.97        52\n",
      "         2_0       0.98      1.00      0.99       112\n",
      "         2_1       0.99      0.93      0.96       109\n",
      "         2_2       0.94      0.98      0.96        94\n",
      "         2_3       0.98      0.99      0.98       139\n",
      "         2_4       1.00      1.00      1.00        50\n",
      "\n",
      "    accuracy                           0.97      1111\n",
      "   macro avg       0.98      0.97      0.97      1111\n",
      "weighted avg       0.98      0.97      0.97      1111\n",
      "\n",
      "0.9747974797479748\n"
     ]
    }
   ],
   "source": [
    "# kth nearest neighbors (KNN) on 40% of data\n",
    "stdscale.fit(feature_train40)\n",
    "feature_train40 = stdscale.transform(feature_train40)\n",
    "feature_test40 = stdscale.transform(feature_test40)\n",
    "\n",
    "knc40 = KNeighborsClassifier()\n",
    "knc40.fit(feature_train40, target_train40)\n",
    "\n",
    "knc40_predict_target = knc40.predict(feature_test40)\n",
    "\n",
    "print(classification_report(target_test40, knc40_predict_target))\n",
    "accuracyknc40 = accuracy_score(target_test40, knc40_predict_target)\n",
    "print(accuracyknc40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a688ac2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0_0       0.96      0.98      0.97        66\n",
      "         0_1       0.99      0.96      0.97        71\n",
      "         0_2       0.97      0.99      0.98        74\n",
      "         0_3       1.00      0.99      0.99        82\n",
      "         1_0       1.00      0.99      0.99        80\n",
      "         1_1       0.99      1.00      0.99        96\n",
      "         1_2       0.99      1.00      0.99        86\n",
      "         1_3       1.00      0.96      0.98        52\n",
      "         2_0       0.99      1.00      1.00       112\n",
      "         2_1       1.00      0.99      1.00       109\n",
      "         2_2       0.98      0.98      0.98        94\n",
      "         2_3       0.99      0.99      0.99       139\n",
      "         2_4       1.00      1.00      1.00        50\n",
      "\n",
      "    accuracy                           0.99      1111\n",
      "   macro avg       0.99      0.99      0.99      1111\n",
      "weighted avg       0.99      0.99      0.99      1111\n",
      "\n",
      "0.9882988298829883\n"
     ]
    }
   ],
   "source": [
    "# svc on 40% of data\n",
    "svc40 = SVC(kernel='linear')\n",
    "svc40.fit(feature_train40, target_train40)\n",
    "\n",
    "svc40_predict_target = svc40.predict(feature_test40)\n",
    "\n",
    "print(classification_report(target_test40,svc40_predict_target))\n",
    "accuracysvc40 = accuracy_score(target_test40, svc40_predict_target)\n",
    "print(accuracysvc40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ccfe62",
   "metadata": {},
   "source": [
    "Mean accuracy for all three experiments using 40% of data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f41f9f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9834983498349835\n"
     ]
    }
   ],
   "source": [
    "# computing mean accuracy score for using 40% of data to train\n",
    "average40 = (accuracyrfc40 + accuracyknc40 + accuracysvc40) / 3\n",
    "print(average40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b468226b",
   "metadata": {},
   "source": [
    "Using only 60% of data for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b0d56bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape (1111, 520)\n",
      "train shape (11962, 520)\n"
     ]
    }
   ],
   "source": [
    "# using 60% of the dataset \n",
    "#randomly select 60% of training data to be included \n",
    "feature_train60, feature_test60, target_train60, target_test60 = train_test_split(features, target, test_size=0.0557, train_size=0.6, random_state=SEED)\n",
    "\n",
    "print(\"test shape\", feature_test60.shape)\n",
    "print(\"train shape\", feature_train60.shape)\n",
    "#ensuring correct number of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d5b10c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0_0       0.98      0.95      0.97        66\n",
      "         0_1       0.95      0.99      0.97        71\n",
      "         0_2       1.00      0.99      0.99        74\n",
      "         0_3       1.00      1.00      1.00        82\n",
      "         1_0       1.00      0.99      0.99        80\n",
      "         1_1       0.99      1.00      0.99        96\n",
      "         1_2       0.99      1.00      0.99        86\n",
      "         1_3       0.91      0.98      0.94        52\n",
      "         2_0       0.99      0.96      0.97       112\n",
      "         2_1       1.00      0.99      1.00       109\n",
      "         2_2       1.00      1.00      1.00        94\n",
      "         2_3       1.00      1.00      1.00       139\n",
      "         2_4       1.00      1.00      1.00        50\n",
      "\n",
      "    accuracy                           0.99      1111\n",
      "   macro avg       0.99      0.99      0.99      1111\n",
      "weighted avg       0.99      0.99      0.99      1111\n",
      "\n",
      "0.9882988298829883\n"
     ]
    }
   ],
   "source": [
    "#random forest model on 60% of the data\n",
    "rfc60 = RandomForestClassifier(n_estimators=13, \n",
    "                             random_state=SEED)\n",
    "rfc60.fit(feature_train60, target_train60)\n",
    "\n",
    "rfc60_predict_target = rfc60.predict(feature_test60)\n",
    "\n",
    "print(classification_report(target_test60,rfc60_predict_target))\n",
    "accuracyrfc60 = accuracy_score(target_test60, rfc60_predict_target)\n",
    "print(accuracyrfc60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bac5e77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0_0       0.98      0.98      0.98        66\n",
      "         0_1       0.96      0.97      0.97        71\n",
      "         0_2       0.96      0.96      0.96        74\n",
      "         0_3       0.98      0.96      0.97        82\n",
      "         1_0       1.00      1.00      1.00        80\n",
      "         1_1       1.00      1.00      1.00        96\n",
      "         1_2       0.97      1.00      0.98        86\n",
      "         1_3       1.00      0.94      0.97        52\n",
      "         2_0       0.97      1.00      0.99       112\n",
      "         2_1       0.99      0.94      0.97       109\n",
      "         2_2       0.97      0.98      0.97        94\n",
      "         2_3       0.98      0.99      0.98       139\n",
      "         2_4       1.00      1.00      1.00        50\n",
      "\n",
      "    accuracy                           0.98      1111\n",
      "   macro avg       0.98      0.98      0.98      1111\n",
      "weighted avg       0.98      0.98      0.98      1111\n",
      "\n",
      "0.9801980198019802\n"
     ]
    }
   ],
   "source": [
    "# kth nearest neighbors (KNN) on 60% of data\n",
    "stdscale.fit(feature_train60)\n",
    "feature_train60 = stdscale.transform(feature_train60)\n",
    "feature_test60 = stdscale.transform(feature_test60)\n",
    "\n",
    "knc60 = KNeighborsClassifier()\n",
    "knc60.fit(feature_train60, target_train60)\n",
    "\n",
    "knc60_predict_target = knc60.predict(feature_test60)\n",
    "\n",
    "print(classification_report(target_test60, knc60_predict_target))\n",
    "accuracyknc60 = accuracy_score(target_test60, knc60_predict_target)\n",
    "print(accuracyknc60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58bbd6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0_0       0.98      0.97      0.98        66\n",
      "         0_1       0.96      0.96      0.96        71\n",
      "         0_2       0.96      0.99      0.97        74\n",
      "         0_3       1.00      0.99      0.99        82\n",
      "         1_0       1.00      0.99      0.99        80\n",
      "         1_1       0.99      1.00      0.99        96\n",
      "         1_2       0.99      1.00      0.99        86\n",
      "         1_3       0.91      0.98      0.94        52\n",
      "         2_0       1.00      0.96      0.98       112\n",
      "         2_1       1.00      0.99      1.00       109\n",
      "         2_2       0.98      0.99      0.98        94\n",
      "         2_3       0.99      0.99      0.99       139\n",
      "         2_4       1.00      1.00      1.00        50\n",
      "\n",
      "    accuracy                           0.98      1111\n",
      "   macro avg       0.98      0.98      0.98      1111\n",
      "weighted avg       0.99      0.98      0.98      1111\n",
      "\n",
      "0.9846984698469847\n"
     ]
    }
   ],
   "source": [
    "#svc on 60% of data\n",
    "svc60 = SVC(kernel='linear')\n",
    "svc60.fit(feature_train60, target_train60)\n",
    "\n",
    "svc60_predict_target = svc60.predict(feature_test60)\n",
    "\n",
    "print(classification_report(target_test60,svc60_predict_target))\n",
    "accuracysvc60 = accuracy_score(target_test60, svc60_predict_target)\n",
    "print(accuracysvc60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d7e753",
   "metadata": {},
   "source": [
    "Mean accuracy for all three experiments using 60% of data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "31bd9a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9843984398439845\n"
     ]
    }
   ],
   "source": [
    "# computing mean accuracy score for using 60% of data to train\n",
    "average60 = (accuracyrfc60 + accuracyknc60 + accuracysvc60) / 3\n",
    "print(average60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da6cc04",
   "metadata": {},
   "source": [
    "Using only 80% of data for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "73c26527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape (1111, 520)\n",
      "train shape (15949, 520)\n"
     ]
    }
   ],
   "source": [
    "# using 80% of the dataset \n",
    "#randomly select 20% of training data to be included \n",
    "feature_train80, feature_test80, target_train80, target_test80 = train_test_split(features, target, test_size=0.0557, train_size=0.8, random_state=SEED)\n",
    "\n",
    "print(\"test shape\", feature_test80.shape)\n",
    "print(\"train shape\", feature_train80.shape)\n",
    "#ensuring correct number of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b231d03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0_0       1.00      0.97      0.98        66\n",
      "         0_1       0.97      1.00      0.99        71\n",
      "         0_2       0.99      1.00      0.99        74\n",
      "         0_3       1.00      0.99      0.99        82\n",
      "         1_0       0.99      1.00      0.99        80\n",
      "         1_1       1.00      0.99      0.99        96\n",
      "         1_2       1.00      1.00      1.00        86\n",
      "         1_3       0.91      1.00      0.95        52\n",
      "         2_0       1.00      0.96      0.98       112\n",
      "         2_1       1.00      1.00      1.00       109\n",
      "         2_2       1.00      1.00      1.00        94\n",
      "         2_3       1.00      1.00      1.00       139\n",
      "         2_4       1.00      1.00      1.00        50\n",
      "\n",
      "    accuracy                           0.99      1111\n",
      "   macro avg       0.99      0.99      0.99      1111\n",
      "weighted avg       0.99      0.99      0.99      1111\n",
      "\n",
      "0.991899189918992\n"
     ]
    }
   ],
   "source": [
    "#random forest model on 80% of the data\n",
    "rfc80 = RandomForestClassifier(n_estimators=13, \n",
    "                             random_state=SEED)\n",
    "rfc80.fit(feature_train80, target_train80)\n",
    "\n",
    "rfc80_predict_target = rfc80.predict(feature_test80)\n",
    "\n",
    "print(classification_report(target_test80,rfc80_predict_target))\n",
    "accuracyrfc80 = accuracy_score(target_test80, rfc80_predict_target)\n",
    "print(accuracyrfc80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cd464f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0_0       1.00      0.98      0.99        66\n",
      "         0_1       0.99      0.99      0.99        71\n",
      "         0_2       0.96      0.97      0.97        74\n",
      "         0_3       0.98      0.98      0.98        82\n",
      "         1_0       1.00      1.00      1.00        80\n",
      "         1_1       1.00      1.00      1.00        96\n",
      "         1_2       0.99      1.00      0.99        86\n",
      "         1_3       1.00      0.96      0.98        52\n",
      "         2_0       0.97      1.00      0.99       112\n",
      "         2_1       0.97      0.95      0.96       109\n",
      "         2_2       0.98      0.97      0.97        94\n",
      "         2_3       0.98      0.99      0.98       139\n",
      "         2_4       1.00      1.00      1.00        50\n",
      "\n",
      "    accuracy                           0.98      1111\n",
      "   macro avg       0.99      0.98      0.98      1111\n",
      "weighted avg       0.98      0.98      0.98      1111\n",
      "\n",
      "0.9837983798379838\n"
     ]
    }
   ],
   "source": [
    "# kth nearest neighbors (KNN) on 80% of data\n",
    "stdscale.fit(feature_train80)\n",
    "feature_train80 = stdscale.transform(feature_train80)\n",
    "feature_test80 = stdscale.transform(feature_test80)\n",
    "\n",
    "knc80 = KNeighborsClassifier()\n",
    "knc80.fit(feature_train80, target_train80)\n",
    "\n",
    "knc80_predict_target = knc80.predict(feature_test80)\n",
    "\n",
    "print(classification_report(target_test80, knc80_predict_target))\n",
    "accuracyknc80 = accuracy_score(target_test80, knc80_predict_target)\n",
    "print(accuracyknc80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "604624e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0_0       0.98      0.97      0.98        66\n",
      "         0_1       0.97      0.99      0.98        71\n",
      "         0_2       0.99      1.00      0.99        74\n",
      "         0_3       1.00      0.99      0.99        82\n",
      "         1_0       1.00      0.99      0.99        80\n",
      "         1_1       0.99      1.00      0.99        96\n",
      "         1_2       0.99      1.00      0.99        86\n",
      "         1_3       0.91      0.98      0.94        52\n",
      "         2_0       1.00      0.96      0.98       112\n",
      "         2_1       1.00      1.00      1.00       109\n",
      "         2_2       0.99      1.00      0.99        94\n",
      "         2_3       1.00      0.99      1.00       139\n",
      "         2_4       1.00      1.00      1.00        50\n",
      "\n",
      "    accuracy                           0.99      1111\n",
      "   macro avg       0.99      0.99      0.99      1111\n",
      "weighted avg       0.99      0.99      0.99      1111\n",
      "\n",
      "0.9891989198919892\n"
     ]
    }
   ],
   "source": [
    "#svc on 80% of data\n",
    "svc80 = SVC(kernel='linear')\n",
    "svc80.fit(feature_train80, target_train80)\n",
    "\n",
    "svc80_predict_target = svc80.predict(feature_test80)\n",
    "\n",
    "print(classification_report(target_test80,svc80_predict_target))\n",
    "accuracysvc80 = accuracy_score(target_test80, svc80_predict_target)\n",
    "print(accuracysvc80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf38e32f",
   "metadata": {},
   "source": [
    "Mean accuracy for all three experiments using 80% of data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2e088d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9882988298829883\n"
     ]
    }
   ],
   "source": [
    "# computing mean accuracy score for using 80% of data to train\n",
    "average80 = (accuracyrfc80 + accuracyknc80 + accuracysvc80) / 3\n",
    "print(average80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da70b76",
   "metadata": {},
   "source": [
    "Using 100% of data for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c2dc260f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape (19937, 520)\n"
     ]
    }
   ],
   "source": [
    "# using 100% of the dataset, no need to split\n",
    "print(\"train shape\", features.shape)\n",
    "#ensuring correct number of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f30dd067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0_0       1.00      1.00      1.00      1059\n",
      "         0_1       1.00      1.00      1.00      1356\n",
      "         0_2       1.00      1.00      1.00      1443\n",
      "         0_3       1.00      1.00      1.00      1391\n",
      "         1_0       1.00      1.00      1.00      1368\n",
      "         1_1       1.00      1.00      1.00      1484\n",
      "         1_2       1.00      1.00      1.00      1396\n",
      "         1_3       0.96      1.00      0.98       948\n",
      "         2_0       1.00      0.98      0.99      1942\n",
      "         2_1       1.00      1.00      1.00      2162\n",
      "         2_2       1.00      1.00      1.00      1577\n",
      "         2_3       1.00      1.00      1.00      2709\n",
      "         2_4       1.00      1.00      1.00      1102\n",
      "\n",
      "    accuracy                           1.00     19937\n",
      "   macro avg       1.00      1.00      1.00     19937\n",
      "weighted avg       1.00      1.00      1.00     19937\n",
      "\n",
      "0.9980438380899834\n"
     ]
    }
   ],
   "source": [
    "#random forest model on 100% of the data\n",
    "rfc100 = RandomForestClassifier(n_estimators=13, \n",
    "                             random_state=SEED)\n",
    "rfc100.fit(features, target)\n",
    "\n",
    "rfc100_predict_target = rfc100.predict(features)\n",
    "\n",
    "print(classification_report(target,rfc100_predict_target))\n",
    "accuracyrfc100 = accuracy_score(target, rfc100_predict_target)\n",
    "print(accuracyrfc100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4d3fd255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0_0       0.99      1.00      0.99      1059\n",
      "         0_1       0.99      0.99      0.99      1356\n",
      "         0_2       0.99      0.98      0.99      1443\n",
      "         0_3       0.99      0.99      0.99      1391\n",
      "         1_0       1.00      1.00      1.00      1368\n",
      "         1_1       1.00      0.99      1.00      1484\n",
      "         1_2       0.99      1.00      0.99      1396\n",
      "         1_3       0.96      0.99      0.97       948\n",
      "         2_0       1.00      0.98      0.99      1942\n",
      "         2_1       0.99      0.99      0.99      2162\n",
      "         2_2       0.99      0.98      0.99      1577\n",
      "         2_3       0.99      1.00      1.00      2709\n",
      "         2_4       1.00      1.00      1.00      1102\n",
      "\n",
      "    accuracy                           0.99     19937\n",
      "   macro avg       0.99      0.99      0.99     19937\n",
      "weighted avg       0.99      0.99      0.99     19937\n",
      "\n",
      "0.9910718764106937\n"
     ]
    }
   ],
   "source": [
    "# kth nearest neighbors (KNN) on 100% of data\n",
    "stdscale.fit(features)\n",
    "features = stdscale.transform(features)\n",
    "\n",
    "knc100 = KNeighborsClassifier()\n",
    "knc100.fit(features, target)\n",
    "\n",
    "knc100_predict_target = knc100.predict(features)\n",
    "\n",
    "print(classification_report(target, knc100_predict_target))\n",
    "accuracyknc100 = accuracy_score(target, knc100_predict_target)\n",
    "print(accuracyknc100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d8cb5380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0_0       1.00      1.00      1.00      1059\n",
      "         0_1       1.00      1.00      1.00      1356\n",
      "         0_2       1.00      1.00      1.00      1443\n",
      "         0_3       1.00      1.00      1.00      1391\n",
      "         1_0       1.00      1.00      1.00      1368\n",
      "         1_1       1.00      1.00      1.00      1484\n",
      "         1_2       1.00      1.00      1.00      1396\n",
      "         1_3       0.96      1.00      0.98       948\n",
      "         2_0       1.00      0.98      0.99      1942\n",
      "         2_1       1.00      1.00      1.00      2162\n",
      "         2_2       1.00      1.00      1.00      1577\n",
      "         2_3       1.00      1.00      1.00      2709\n",
      "         2_4       1.00      1.00      1.00      1102\n",
      "\n",
      "    accuracy                           1.00     19937\n",
      "   macro avg       1.00      1.00      1.00     19937\n",
      "weighted avg       1.00      1.00      1.00     19937\n",
      "\n",
      "0.9978432060992125\n"
     ]
    }
   ],
   "source": [
    "#svc on 100% of data\n",
    "svc100 = SVC(kernel='linear')\n",
    "svc100.fit(features, target)\n",
    "\n",
    "svc100_predict_target = svc100.predict(features)\n",
    "\n",
    "print(classification_report(target,svc100_predict_target))\n",
    "accuracysvc100 = accuracy_score(target, svc100_predict_target)\n",
    "print(accuracysvc100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70845277",
   "metadata": {},
   "source": [
    "Mean accuracy for all three experiments using 100% of data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "edc96e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9956529735332965\n"
     ]
    }
   ],
   "source": [
    "# computing mean accuracy score for using 100% of data to train\n",
    "average100 = (accuracyrfc100 + accuracyknc100 + accuracysvc100) / 3\n",
    "print(average100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea604e4",
   "metadata": {},
   "source": [
    "Scatterplot of averages for each percentage (inludes all 3 experiments for each %)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9a06e044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting averages:\n",
    "\n",
    "#variables:\n",
    "percent_data = [20, 40, 60, 80, 100] #including each percentage datapoint that I considered \n",
    "average = [average20, average40, average60, average80, average100] #all the averages for each percentage\n",
    "\n",
    "#configuring plot:\n",
    "plt.figure(figsize=(10, 5)) #size of chart diplayed \n",
    "plt.scatter(percent_data, average, color='red', marker='o') #creates dot scatter plot with percentages on x axis and averages on y axis\n",
    "plt.xlabel('Percent used For Training Data') #labels x axis \n",
    "plt.ylabel('Average Accuracy') #labels y axis \n",
    "plt.title('Average accuracy based on Training Size') #labels title \n",
    "plt.grid(True) #adds grid \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba24292f",
   "metadata": {},
   "source": [
    "# Result: More data results in higher average accuracy scores, however, it is important to avoid using all the data as training data because it is possible the model will overfit the data and be unable to replicate the same accuracy on a test set. More data is better as long as there is a sufficient amount of data left over for the testing set. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
